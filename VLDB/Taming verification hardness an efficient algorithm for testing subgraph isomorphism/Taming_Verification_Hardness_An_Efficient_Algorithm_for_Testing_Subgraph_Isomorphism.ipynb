{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Taming Verification Hardness: An Efficient Algorithm for Testing Subgraph Isomorphism",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**QuickSI**"
      ],
      "metadata": {
        "id": "4mYlYyAxAs8q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This paper use the idea of **minimum spanning tree** to construct matching order to reduce search space.\n",
        "\n",
        "Although subgraph matching usually have three steps, this paper focus on the last two, that is, **matching order generation and enumeration procedure**.\n",
        "\n",
        "For matching order generation part, the authors first calculate **weights** for each node and each edge in the query graph based on the **frequency** of the type appearing in the graph data(because the algorithm of minimum spanning tree needs weights).\n",
        "\n",
        "Then they perform an algorithm similar to Prim's algorithm to construct the matching order. At the begining, they select an edge based on the **degree of the nodes** it linked. They get the **minimum** one, beacause the **importance of edge** between them would be larger. They put these two nodes in the matching order sequence.\n",
        "\n",
        "After that, they check **each edge** linked to nodes in the maching order sequence to get the next node. How they select the next node(edge)? they first get edges with **minimum weights**(appear **least time** in graph data, so it's easy to make sure. This idea is similar to select the node with **max degree**). And then check the **indegree** of the one end of the edge and get the edges with **maximum** one. This is reasonable, because we want to select a node that has **as many edges as possible** with node we already put in the matching order(this would help reduce the search space). If there're still multiple backup nodes(edges), we should then get the edge with **minimum degree** of one end node(the node would be selected as the next node in the matching order. Why minimum degree? because we already make sure it has many edges with nodes in the sequence. If we find the one with minimum degree, then this node may be very important to this structure now). Finally, if there's still a tie, we should randomly select one.\n",
        "\n",
        "Perform these steps number of nodes times, we would get a valid matching order.\n",
        "\n",
        "Then they use the enumeration procedure like **UllmanAlgorithm**, but with more conditions to reduce search space."
      ],
      "metadata": {
        "id": "4buvqw4zAtOe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaBBlaT8pJmY",
        "outputId": "61f0b2ca-258a-4882-992b-65498ef3421c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'SubgraphMatching' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/RapidsAtHKUST/SubgraphMatching.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import random"
      ],
      "metadata": {
        "id": "f-PDyCoOpPJ2"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class graph():\n",
        "  def __init__(self, graphid, node2label, node2degree, edges):\n",
        "    self.graphid = graphid\n",
        "    self.node2label = node2label\n",
        "    self.node2degree = node2degree\n",
        "    self.edges = edges\n",
        "    self.candidateset = defaultdict(set)\n",
        "    self.label2node = defaultdict(set)\n",
        "    for node in self.node2label:\n",
        "      self.label2node[self.node2label[node]].add(node)\n",
        "    self.phi = []\n",
        "    self.phiparent = {}\n",
        "\n",
        "  def reset(self):\n",
        "    self.candidateset = defaultdict(set)\n",
        "    self.phi = []\n",
        "    self.phiparent = {}"
      ],
      "metadata": {
        "id": "WGtl0MhgpQMn"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_graph(filepath, filename):\n",
        "  global qcount\n",
        "  global gcount\n",
        "\n",
        "  node2label = {}\n",
        "  node2degree = {}\n",
        "  edges = defaultdict(set)\n",
        "  f = open(filepath, \"r\", encoding=\"utf-8\")\n",
        "\n",
        "  _, nodenum, edgenum = f.readline().strip().split()\n",
        "  for i in range(int(nodenum)):\n",
        "    _, nodeid, nodelabel, nodedegree = f.readline().strip().split()\n",
        "    node2label[int(nodeid)] = int(nodelabel)\n",
        "    node2degree[int(nodeid)] = int(nodedegree)  \n",
        "  for i in range(int(edgenum)):\n",
        "    _, node1, node2 = f.readline().strip().split()\n",
        "    edges[int(node1)].add(int(node2))\n",
        "    edges[int(node2)].add(int(node1))\n",
        "\n",
        "  f.close()\n",
        "  g = graph(filename, node2label, node2degree, edges)\n",
        "\n",
        "  return g"
      ],
      "metadata": {
        "id": "rwr8deRDpRKf"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qcount = 0\n",
        "gcount = 0\n",
        "\n",
        "import os\n",
        "qs = []\n",
        "qdir = \"SubgraphMatching/test/query_graph\"\n",
        "for f in os.listdir(qdir):\n",
        "  filepath = os.path.join(qdir, f)\n",
        "  qs.append(get_graph(filepath, f))\n",
        "\n",
        "gs = []\n",
        "gdir = \"SubgraphMatching/test/data_graph\"\n",
        "for f in os.listdir(gdir):\n",
        "  filepath = os.path.join(gdir, f)\n",
        "  gs.append(get_graph(filepath, f))\n",
        "\n",
        "print(len(qs))\n",
        "print(len(gs))\n",
        "\n",
        "f = open(\"SubgraphMatching/test/expected_output.res\", \"r\", encoding=\"utf-8\")\n",
        "lines = f.readlines()\n",
        "f.close()\n",
        "\n",
        "expects = {}\n",
        "for line in lines:\n",
        "  name, times = line.strip().split(\":\")\n",
        "  expects[name + \".graph\"] = int(times)\n",
        "print(len(expects))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYlxMNejpSW3",
        "outputId": "8c6ab412-111e-4946-d031-8bbfcfe615fc"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "1\n",
            "200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def QuickSI_MOG(q, g):\n",
        "  wnodes = {}\n",
        "  wedges = {}\n",
        "  for node in q.node2label:\n",
        "    wnodes[node] = len(g.label2node[q.node2label[node]])\n",
        "\n",
        "  ngedges = defaultdict(int)\n",
        "  for node1 in g.edges:\n",
        "    for node2 in g.edges[node1]:\n",
        "      edge = (g.node2label[node1], g.node2label[node2])\n",
        "      ngedges[edge] += 1\n",
        "\n",
        "  for node1 in q.edges:\n",
        "    for node2 in q.edges[node1]:\n",
        "      edge = (q.node2label[node1], q.node2label[node2])\n",
        "      if (node1, node2) in wedges:\n",
        "        continue\n",
        "      wedges[(node1, node2)] = ngedges[edge]\n",
        "\n",
        "\n",
        "  p = set()\n",
        "  minedge = min(wedges, key=wedges.get)\n",
        "  for edge in wedges:\n",
        "    if wedges[edge] == wedges[minedge]:\n",
        "      p.add(edge)\n",
        "  \n",
        "  tmp = p\n",
        "  p = set()\n",
        "  if len(tmp) > 1:\n",
        "    for edge1 in tmp:\n",
        "      sumdegree1 = q.node2degree[edge1[0]] + q.node2degree[edge1[1]]\n",
        "      flag = True\n",
        "      for edge2 in tmp:\n",
        "        sumdegree2 = q.node2degree[edge2[0]] + q.node2degree[edge2[1]]\n",
        "        if sumdegree2 < sumdegree1:\n",
        "          flag = False\n",
        "          break\n",
        "      if flag:\n",
        "        p.add(edge1)\n",
        "    e = random.choice(list(p))\n",
        "  else:\n",
        "    e = list(tmp)[0]\n",
        "  \n",
        "  q.phi.append(e[0])\n",
        "  q.phi.append(e[1])\n",
        "  q.phiparent[e[0]] = -1\n",
        "  q.phiparent[e[1]] = e[0]\n",
        "  visited = set()\n",
        "  visited.add(e[0])\n",
        "  visited.add(e[1])\n",
        "\n",
        "  wedges.pop(e)\n",
        "  wedges.pop((e[1], e[0]))\n",
        "\n",
        "  while len(q.phi) != len(q.node2label):\n",
        "    p = set()\n",
        "    for edge in wedges:\n",
        "      if (edge[0] in visited and edge[1] not in visited) or (edge[1] in visited and edge[0] not in visited):\n",
        "        p.add(edge)\n",
        "\n",
        "    tmp = p\n",
        "    p = set()\n",
        "    for edge1 in tmp:\n",
        "      flag = True\n",
        "      for edge2 in tmp:\n",
        "        if wedges[edge2] < wedges[edge1]:\n",
        "          flag = False\n",
        "          break\n",
        "      if flag:\n",
        "        p.add(edge1)\n",
        "    \n",
        "    tmp = p\n",
        "    p = set()\n",
        "\n",
        "    if len(tmp) > 1:\n",
        "      for edge1 in tmp:\n",
        "        flag = True\n",
        "        indg1 = set()\n",
        "        indg1 |= visited\n",
        "        indg1.add(edge1[1])\n",
        "        totalindg1 = 0\n",
        "        for node in indg1:\n",
        "          totalindg1 += q.node2degree[node]\n",
        "\n",
        "        for edge2 in tmp:\n",
        "          indg2 = set()\n",
        "          indg2 |= visited\n",
        "          indg2.add(edge2[1])\n",
        "          totalindg2 = 0\n",
        "          for node in indg2:\n",
        "            totalindg2 += q.node2degree[node]\n",
        "          if totalindg1 < totalindg2:\n",
        "            flag = False\n",
        "            break\n",
        "        if flag:\n",
        "          p.add(edge1)\n",
        "    else:\n",
        "      p = tmp\n",
        "    tmp = p\n",
        "\n",
        "\n",
        "    p = set()\n",
        "    if len(tmp) > 1:\n",
        "      for edge1 in tmp:\n",
        "        flag = True\n",
        "        degree1 = q.node2degree[edge1[1]]\n",
        "        for edge2 in tmp:\n",
        "          degree2 = q.node2degree[edge2[1]]\n",
        "          if degree1 > degree2:\n",
        "            flag = False\n",
        "            break\n",
        "        if flag:\n",
        "          p.add(edge1)\n",
        "    else:\n",
        "      p = tmp\n",
        "    \n",
        "\n",
        "    if len(p) > 1:\n",
        "      e = random.choice(list(p))\n",
        "    else:\n",
        "      e = list(p)[0]\n",
        "    \n",
        "    if e[1] not in visited:\n",
        "      q.phi.append(e[1])\n",
        "      visited.add(e[1])\n",
        "      q.phiparent[e[1]] = e[0]\n",
        "    else:\n",
        "      q.phi.append(e[0])\n",
        "      visited.add(e[0])\n",
        "      q.phiparent[e[0]] = e[1]\n",
        "    \n",
        "    for edge in wedges.copy():\n",
        "      if edge[0] in visited and edge[1] in visited:\n",
        "        wedges.pop(edge)\n",
        "    "
      ],
      "metadata": {
        "id": "ZGjZum4vpTfZ"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def QuickSI_EP(q, g, m, i, totalresult): # not equal to the original code\n",
        "  if i == len(q.phi) + 1:\n",
        "    totalresult.append(m.copy())\n",
        "    return \n",
        "  result = {}\n",
        "  u = -1\n",
        "  for node in q.phi:\n",
        "    if node not in m:\n",
        "      u = node\n",
        "      break\n",
        "\n",
        "  lc = set()\n",
        "\n",
        "  if i == 1:\n",
        "    vs = g.label2node[q.node2label[u]]\n",
        "    for v in vs:\n",
        "      if g.node2degree[v] >= q.node2degree[u]:\n",
        "        lc.add(v)\n",
        "  else:\n",
        "    for v in g.edges[m[q.phiparent[u]]]:\n",
        "      if q.node2label[u] == g.node2label[v] and g.node2degree[v] >= q.node2degree[u]:\n",
        "        flag = True\n",
        "        for node in q.phi:\n",
        "          if node == u:\n",
        "            break\n",
        "          if node == q.phiparent[u]:\n",
        "            continue\n",
        "          #if m[node] not in g.edges[v]:\n",
        "          if v == m[node] or (m[node] not in g.edges[v] and (node in q.edges[u] or u in q.edges[node])):\n",
        "            flag = False\n",
        "            break\n",
        "        if flag:\n",
        "          lc.add(v)\n",
        "\n",
        "  for node in lc:\n",
        "    if node not in set(m.values()):\n",
        "      m[u] = node\n",
        "      QuickSI_EP(q, g, m, i + 1, totalresult)\n",
        "      m.pop(u)"
      ],
      "metadata": {
        "id": "fDp50EVxpVtF"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries = {}\n",
        "for g in gs:\n",
        "  for q in qs:\n",
        "    q.reset()\n",
        "    QuickSI_MOG(q, g)\n",
        "    totalresult = []\n",
        "    QuickSI_EP(q, g, {}, 1, totalresult)\n",
        "    queries[q.graphid] = len(totalresult)\n",
        "\n",
        "print(queries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8JHAj4TpXBH",
        "outputId": "7bb92526-56e8-4a8c-cf1f-895cd0442cc4"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query_dense_16_91.graph': 3, 'query_dense_16_96.graph': 17, 'query_dense_16_87.graph': 12, 'query_dense_16_179.graph': 184, 'query_dense_16_155.graph': 16, 'query_dense_16_103.graph': 48, 'query_dense_16_134.graph': 17, 'query_dense_16_160.graph': 2688, 'query_dense_16_107.graph': 21, 'query_dense_16_57.graph': 3, 'query_dense_16_142.graph': 16, 'query_dense_16_71.graph': 9, 'query_dense_16_161.graph': 44, 'query_dense_16_152.graph': 432, 'query_dense_16_60.graph': 10, 'query_dense_16_158.graph': 2, 'query_dense_16_115.graph': 10, 'query_dense_16_81.graph': 124, 'query_dense_16_168.graph': 75, 'query_dense_16_5.graph': 4, 'query_dense_16_53.graph': 12, 'query_dense_16_124.graph': 2, 'query_dense_16_68.graph': 256, 'query_dense_16_56.graph': 4, 'query_dense_16_27.graph': 8, 'query_dense_16_141.graph': 20, 'query_dense_16_65.graph': 2, 'query_dense_16_136.graph': 1, 'query_dense_16_14.graph': 2, 'query_dense_16_22.graph': 9, 'query_dense_16_43.graph': 3, 'query_dense_16_84.graph': 8, 'query_dense_16_183.graph': 4, 'query_dense_16_41.graph': 8, 'query_dense_16_148.graph': 2, 'query_dense_16_126.graph': 156, 'query_dense_16_63.graph': 44, 'query_dense_16_93.graph': 22, 'query_dense_16_154.graph': 12, 'query_dense_16_199.graph': 2, 'query_dense_16_163.graph': 8, 'query_dense_16_185.graph': 44, 'query_dense_16_4.graph': 6, 'query_dense_16_23.graph': 6, 'query_dense_16_19.graph': 2, 'query_dense_16_138.graph': 12, 'query_dense_16_50.graph': 88, 'query_dense_16_130.graph': 16, 'query_dense_16_109.graph': 68, 'query_dense_16_38.graph': 180, 'query_dense_16_146.graph': 24, 'query_dense_16_45.graph': 8, 'query_dense_16_125.graph': 8, 'query_dense_16_190.graph': 3, 'query_dense_16_10.graph': 32, 'query_dense_16_40.graph': 12, 'query_dense_16_8.graph': 560, 'query_dense_16_121.graph': 30, 'query_dense_16_123.graph': 1, 'query_dense_16_34.graph': 2, 'query_dense_16_101.graph': 2, 'query_dense_16_188.graph': 8, 'query_dense_16_151.graph': 138, 'query_dense_16_59.graph': 1680, 'query_dense_16_129.graph': 8, 'query_dense_16_99.graph': 260, 'query_dense_16_54.graph': 33, 'query_dense_16_67.graph': 1, 'query_dense_16_69.graph': 1, 'query_dense_16_198.graph': 15, 'query_dense_16_7.graph': 2, 'query_dense_16_164.graph': 480, 'query_dense_16_184.graph': 60, 'query_dense_16_62.graph': 8, 'query_dense_16_116.graph': 1, 'query_dense_16_187.graph': 2, 'query_dense_16_118.graph': 136, 'query_dense_16_31.graph': 8, 'query_dense_16_92.graph': 18, 'query_dense_16_29.graph': 24, 'query_dense_16_98.graph': 8, 'query_dense_16_9.graph': 42, 'query_dense_16_172.graph': 16, 'query_dense_16_83.graph': 3, 'query_dense_16_137.graph': 5, 'query_dense_16_33.graph': 4, 'query_dense_16_97.graph': 56, 'query_dense_16_173.graph': 24, 'query_dense_16_133.graph': 6, 'query_dense_16_102.graph': 8, 'query_dense_16_113.graph': 6, 'query_dense_16_49.graph': 178, 'query_dense_16_149.graph': 1, 'query_dense_16_25.graph': 4, 'query_dense_16_82.graph': 12, 'query_dense_16_174.graph': 6, 'query_dense_16_181.graph': 8, 'query_dense_16_75.graph': 32, 'query_dense_16_6.graph': 132, 'query_dense_16_162.graph': 48, 'query_dense_16_12.graph': 2, 'query_dense_16_95.graph': 354, 'query_dense_16_189.graph': 1, 'query_dense_16_169.graph': 44, 'query_dense_16_61.graph': 40, 'query_dense_16_105.graph': 2, 'query_dense_16_73.graph': 6, 'query_dense_16_37.graph': 1, 'query_dense_16_77.graph': 4, 'query_dense_16_70.graph': 42, 'query_dense_16_111.graph': 2, 'query_dense_16_47.graph': 16, 'query_dense_16_30.graph': 2, 'query_dense_16_108.graph': 46, 'query_dense_16_200.graph': 4, 'query_dense_16_131.graph': 3, 'query_dense_16_120.graph': 24, 'query_dense_16_13.graph': 12, 'query_dense_16_24.graph': 12, 'query_dense_16_88.graph': 12, 'query_dense_16_28.graph': 5, 'query_dense_16_44.graph': 12, 'query_dense_16_150.graph': 6, 'query_dense_16_110.graph': 2, 'query_dense_16_16.graph': 4, 'query_dense_16_182.graph': 54, 'query_dense_16_119.graph': 8, 'query_dense_16_104.graph': 38, 'query_dense_16_186.graph': 10, 'query_dense_16_26.graph': 17, 'query_dense_16_3.graph': 8, 'query_dense_16_86.graph': 1, 'query_dense_16_159.graph': 12, 'query_dense_16_76.graph': 41, 'query_dense_16_127.graph': 12, 'query_dense_16_85.graph': 19, 'query_dense_16_106.graph': 2, 'query_dense_16_72.graph': 24, 'query_dense_16_80.graph': 13, 'query_dense_16_94.graph': 2, 'query_dense_16_35.graph': 2, 'query_dense_16_196.graph': 2, 'query_dense_16_166.graph': 128, 'query_dense_16_78.graph': 12, 'query_dense_16_147.graph': 1526, 'query_dense_16_175.graph': 8, 'query_dense_16_157.graph': 2, 'query_dense_16_42.graph': 32, 'query_dense_16_79.graph': 2, 'query_dense_16_90.graph': 1564, 'query_dense_16_52.graph': 6, 'query_dense_16_17.graph': 4, 'query_dense_16_89.graph': 12, 'query_dense_16_100.graph': 16, 'query_dense_16_193.graph': 2, 'query_dense_16_156.graph': 6, 'query_dense_16_64.graph': 1, 'query_dense_16_48.graph': 4, 'query_dense_16_195.graph': 2, 'query_dense_16_145.graph': 1, 'query_dense_16_176.graph': 12, 'query_dense_16_132.graph': 20, 'query_dense_16_167.graph': 6, 'query_dense_16_135.graph': 6, 'query_dense_16_51.graph': 50, 'query_dense_16_177.graph': 72, 'query_dense_16_178.graph': 1, 'query_dense_16_55.graph': 1, 'query_dense_16_11.graph': 288, 'query_dense_16_144.graph': 1, 'query_dense_16_117.graph': 4, 'query_dense_16_20.graph': 2, 'query_dense_16_2.graph': 80, 'query_dense_16_15.graph': 60, 'query_dense_16_112.graph': 2, 'query_dense_16_165.graph': 208, 'query_dense_16_140.graph': 8, 'query_dense_16_66.graph': 3, 'query_dense_16_139.graph': 12, 'query_dense_16_191.graph': 4, 'query_dense_16_143.graph': 4, 'query_dense_16_114.graph': 4, 'query_dense_16_36.graph': 3, 'query_dense_16_122.graph': 16, 'query_dense_16_46.graph': 30, 'query_dense_16_180.graph': 1, 'query_dense_16_18.graph': 2, 'query_dense_16_197.graph': 8, 'query_dense_16_39.graph': 1, 'query_dense_16_32.graph': 2, 'query_dense_16_1.graph': 3, 'query_dense_16_74.graph': 8, 'query_dense_16_194.graph': 1, 'query_dense_16_170.graph': 18, 'query_dense_16_128.graph': 104, 'query_dense_16_58.graph': 3, 'query_dense_16_153.graph': 10, 'query_dense_16_171.graph': 14, 'query_dense_16_21.graph': 2, 'query_dense_16_192.graph': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flag = True\n",
        "for name in expects:\n",
        "  if expects[name] != queries[name]:\n",
        "    print(name)\n",
        "    flag = False\n",
        "if flag:\n",
        "  print(\"correct\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ei9z06_pYnj",
        "outputId": "dbd7d66f-084f-4e64-8200-a727e488ce79"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct\n"
          ]
        }
      ]
    }
  ]
}