{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**DAF(DPiso)**"
      ],
      "metadata": {
        "id": "yBJtpm2YIRSU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a subgraph maching algorithm using the idea of dynamic programming.\n",
        "\n",
        "Also, this algorithm uses the classic three-step way to get the result. At fitst, the authors generate a **DAG graph** to get the parent-child relationship between all nodes. And then they use the **classic filters** like NLF, DF and so on to initialize candidate set for each node in the query graph.\n",
        "\n",
        "Then for each candidate node in the data graph, the authors check the neighbors of them who has the same label as the node in query graph. They first remove candidates based on **the number of appearance** of the children in the DAG and then the parents in the DAG. They iterate this procedure 3 times to get the optimal candidate set for each node.\n",
        "\n",
        "For the matching order generation part, they use a **weight matrix**: **weights[qnode][gnode]**. To generation this weight matrix, they use a auxiliary structure **edgematrix[qnode][qneighbor][gnode]** to store the intersection between the neighbors of gnode and candidates of qneighbor, where qnode is the node we are processing, qneighbor are the neighbors of it, gnode are the candidates of qnode. \n",
        "\n",
        "Based on the weights of candidates set for each node, we could optimize the enumeration procedure while matching node with its candidates. It also use BFS order to process nodes in query graph, but for each query graph node they are processing, **the order of candidates is not random**. Other than that, they proposes a **failing set** structure to reduce the search sapce of enumeration procedure. The idea is that, while during enumeration, we meeting a conflict or empty candidate, that means this node would conflict with the ancestor in the BFS tree with its candidate now. In this case, for the current node, we should mark the failing set as **itself and its ancestor** with the conflict candidates, so we don't have to continue process this candidate in other sub-tree of this one."
      ],
      "metadata": {
        "id": "j3K_mRVuIRkX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZEDkdAsEHqh",
        "outputId": "3227f6a4-275c-4427-ce73-0194c62ab157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'SubgraphMatching' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/RapidsAtHKUST/SubgraphMatching.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HQ-x6q3EUx9"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from queue import PriorityQueue\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPfZ_vBLEV4N"
      },
      "outputs": [],
      "source": [
        "class graph():\n",
        "  def __init__(self, graphid, node2label, node2degree, edges):\n",
        "    self.graphid = graphid\n",
        "    self.node2label = node2label\n",
        "    self.node2degree = node2degree\n",
        "    self.edges = edges\n",
        "    self.candidateset = defaultdict(set)\n",
        "    self.label2node = defaultdict(set)\n",
        "    for node in self.node2label:\n",
        "      self.label2node[self.node2label[node]].add(node)\n",
        "    self.phi = []\n",
        "    self.phiparent = {}\n",
        "    self.dagparents = defaultdict(set)\n",
        "    self.dagchildren = defaultdict(set)\n",
        "    self.weights = defaultdict(dict)\n",
        "\n",
        "  def reset(self):\n",
        "    self.candidateset = defaultdict(set)\n",
        "    self.phi = []\n",
        "    self.phiparent = {}\n",
        "    self.dagparents = defaultdict(set)\n",
        "    self.dagchildren = defaultdict(set)\n",
        "    self.weights = defaultdict(dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVBfbTFrEXCJ"
      },
      "outputs": [],
      "source": [
        "def get_graph(filepath, filename):\n",
        "  global qcount\n",
        "  global gcount\n",
        "\n",
        "  node2label = {}\n",
        "  node2degree = {}\n",
        "  edges = defaultdict(set)\n",
        "  f = open(filepath, \"r\", encoding=\"utf-8\")\n",
        "\n",
        "  _, nodenum, edgenum = f.readline().strip().split()\n",
        "  for i in range(int(nodenum)):\n",
        "    _, nodeid, nodelabel, nodedegree = f.readline().strip().split()\n",
        "    node2label[int(nodeid)] = int(nodelabel)\n",
        "    node2degree[int(nodeid)] = int(nodedegree)  \n",
        "  for i in range(int(edgenum)):\n",
        "    _, node1, node2 = f.readline().strip().split()\n",
        "    edges[int(node1)].add(int(node2))\n",
        "    edges[int(node2)].add(int(node1))\n",
        "\n",
        "  f.close()\n",
        "  g = graph(filename, node2label, node2degree, edges)\n",
        "\n",
        "  return g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO3EXAJhEXi5",
        "outputId": "d04178af-1ac7-40d6-dd40-4a5871adbac6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200\n",
            "1\n",
            "200\n"
          ]
        }
      ],
      "source": [
        "qcount = 0\n",
        "gcount = 0\n",
        "\n",
        "import os\n",
        "qs = []\n",
        "qdir = \"SubgraphMatching/test/query_graph\"\n",
        "for f in os.listdir(qdir):\n",
        "  filepath = os.path.join(qdir, f)\n",
        "  qs.append(get_graph(filepath, f))\n",
        "\n",
        "gs = []\n",
        "gdir = \"SubgraphMatching/test/data_graph\"\n",
        "for f in os.listdir(gdir):\n",
        "  filepath = os.path.join(gdir, f)\n",
        "  gs.append(get_graph(filepath, f))\n",
        "\n",
        "print(len(qs))\n",
        "print(len(gs))\n",
        "\n",
        "f = open(\"SubgraphMatching/test/expected_output.res\", \"r\", encoding=\"utf-8\")\n",
        "lines = f.readlines()\n",
        "f.close()\n",
        "\n",
        "expects = {}\n",
        "for line in lines:\n",
        "  name, times = line.strip().split(\":\")\n",
        "  expects[name + \".graph\"] = int(times)\n",
        "print(len(expects))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abpYWaVxEdEu"
      },
      "outputs": [],
      "source": [
        "def DAF_CSG(q, g, k):\n",
        "  for qnode in q.node2label:\n",
        "    label = q.node2label[qnode]\n",
        "    for gnode in g.label2node[label]:\n",
        "      if q.node2degree[qnode] <= g.node2degree[gnode]:\n",
        "        q.candidateset[qnode].add(gnode)\n",
        "\n",
        "  qneighborlabels = defaultdict(lambda: defaultdict(int))\n",
        "  qlabelfreq = defaultdict(int)\n",
        "  for qnode in q.node2label:\n",
        "    qlabelfreq[q.node2label[qnode]] += 1\n",
        "    qneighbors = q.edges[qnode]\n",
        "    for qneighbor in qneighbors:\n",
        "      qneighborlabels[qnode][q.node2label[qneighbor]] += 1\n",
        "  \n",
        "  gneighborlabels = defaultdict(lambda: defaultdict(int))\n",
        "  glabelfreq = defaultdict(int)\n",
        "  for gnode in g.node2label:\n",
        "    glabelfreq[g.node2label[gnode]] += 1\n",
        "    gneighbors = g.edges[gnode]\n",
        "    for gneighbor in gneighbors:\n",
        "      gneighborlabels[gnode][g.node2label[gneighbor]] += 1\n",
        "  \n",
        "  for qnode in q.node2label:\n",
        "    for gnode in q.candidateset[qnode].copy():\n",
        "      for label in qneighborlabels[qnode]:\n",
        "        if qneighborlabels[qnode][label] > gneighborlabels[gnode][label]:\n",
        "          q.candidateset[qnode].remove(gnode)\n",
        "          break\n",
        "\n",
        "  for qnode in q.node2label:\n",
        "    qneighbors = q.edges[qnode]\n",
        "    for qneighbor in qneighbors:\n",
        "      for nodecandidate in q.candidateset[qnode].copy():\n",
        "        if len(g.edges[nodecandidate] & q.candidateset[qneighbor]) == 0:\n",
        "          q.candidateset[qnode].remove(nodecandidate)\n",
        "  \n",
        "  scores = {}\n",
        "  for qnode in q.node2label:\n",
        "    scores[qnode] = len(q.candidateset[qnode]) / q.node2degree[qnode]\n",
        "  \n",
        "  r = min(scores, key=scores.get)\n",
        "\n",
        "  queue = [r]\n",
        "  visited = set()\n",
        "  popped = set()\n",
        "  visited.add(r)\n",
        "  b = 0\n",
        "  e = 1\n",
        "  while (b < e):\n",
        "    tmp = queue[b:e]\n",
        "    tmp.sort(key = lambda x: -q.node2degree[x])\n",
        "    tmp.sort(key = lambda x: (glabelfreq[q.node2label[x]], q.node2label[x]))\n",
        "    queue[b:e] = tmp\n",
        "    cure = e\n",
        "    while(b < cure):\n",
        "      parent = queue[b]\n",
        "      b += 1\n",
        "      popped.add(parent)\n",
        "      for child in q.edges[parent]:\n",
        "        if child not in popped:\n",
        "          q.dagchildren[parent].add(child)\n",
        "          q.dagparents[child].add(parent)\n",
        "          if child not in visited:\n",
        "            visited.add(child)\n",
        "            q.phi.append(child)\n",
        "            q.phiparent[child] = parent\n",
        "            queue.append(child)\n",
        "            e += 1\n",
        "  q.phi = queue\n",
        "\n",
        "  def prunecandidates(q, g, qnode, pruneneighbors):\n",
        "    qlabel = q.node2label[qnode]\n",
        "    qdegree = q.node2degree[qnode]\n",
        "    count = 0\n",
        "    updatedflagcount = 0\n",
        "    pivots = pruneneighbors[qnode]\n",
        "    updatedflag = defaultdict(int)\n",
        "    flag = defaultdict(int)\n",
        "    for pivot in pivots:\n",
        "      for vnode in q.candidateset[pivot]:\n",
        "        vneighbors = g.edges[vnode]\n",
        "        intersection = vneighbors & g.label2node[qlabel]\n",
        "        for vneighbor in intersection:\n",
        "          if flag[vneighbor] == count and g.node2degree[vneighbor] >= qdegree:\n",
        "            flag[vneighbor] += 1\n",
        "            if count == 0:\n",
        "              updatedflag[updatedflagcount] = vneighbor\n",
        "              updatedflagcount += 1\n",
        "      count += 1\n",
        "    \n",
        "    for candidate in q.candidateset[qnode].copy():\n",
        "      if flag[candidate] != count:\n",
        "        q.candidateset[qnode].remove(candidate)\n",
        "\n",
        "\n",
        "  reverseorder = q.phi.copy()\n",
        "  reverseorder.reverse()\n",
        "  \n",
        "  for prune in range(k):\n",
        "    if (prune % 2 == 0): \n",
        "      for qnode in q.phi:\n",
        "        prunecandidates(q, g, qnode, q.dagparents)\n",
        "    else:\n",
        "      for qnode in reverseorder[1:]:\n",
        "        prunecandidates(q, g, qnode, q.dagchildren)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WybXxIS5EdVm"
      },
      "outputs": [],
      "source": [
        "def DAF_MOG(q, g):\n",
        "  edgematrix = defaultdict(lambda: defaultdict(lambda: defaultdict(set)))\n",
        "  for qnode in q.node2label:\n",
        "    for qneighbor in q.edges[qnode]:\n",
        "      for gnode in q.candidateset[qnode]:\n",
        "        gnodeneighbors = g.edges[gnode]\n",
        "        qneighborcandidateset = q.candidateset[qneighbor]\n",
        "        intersection = gnodeneighbors & qneighborcandidateset\n",
        "        edgematrix[qnode][qneighbor][gnode] = intersection\n",
        "\n",
        "  reverseorder = q.phi.copy()\n",
        "  reverseorder.reverse()\n",
        "\n",
        "  for qnode in q.node2label:\n",
        "    for gnode in q.candidateset[qnode]:\n",
        "      q.weights[qnode][gnode] = 17373362\n",
        "\n",
        "  for node in reverseorder:\n",
        "    setone = True\n",
        "    for child in q.dagchildren[node]:\n",
        "      if len(q.dagparents[child]) == 1:\n",
        "        setone = False\n",
        "        for candidate in q.candidateset[node]:\n",
        "          weight = 0\n",
        "          for intersect in edgematrix[qnode][child][candidate]:\n",
        "            weight += q.weights[child][intersect]\n",
        "          \n",
        "          if weight < q.weights[node][candidate]:\n",
        "            q.weights[node][candidate] = weight\n",
        "    if setone:\n",
        "      for candidate in q.candidateset[node]:\n",
        "        q.weights[node][candidate] = 1\n",
        "\n",
        "  return edgematrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9XoG54MEdoM"
      },
      "outputs": [],
      "source": [
        "\"\"\"def DAF_EP(q, g, m, i, totalresult): # not equal to the original code\n",
        "  if i == len(q.phi) + 1:\n",
        "    totalresult.append(m.copy())\n",
        "    return \n",
        "  result = {}\n",
        "  u = -1\n",
        "  for node in q.phi:\n",
        "    if node not in m:\n",
        "      u = node\n",
        "      break\n",
        "\n",
        "  lc = set()\n",
        "\n",
        "  if i == 1:\n",
        "    vs = g.label2node[q.node2label[u]]\n",
        "    for v in vs:\n",
        "      if g.node2degree[v] >= q.node2degree[u]:\n",
        "        lc.add(v)\n",
        "  else:\n",
        "    for v in g.edges[m[q.phiparent[u]]]:\n",
        "      if q.node2label[u] == g.node2label[v] and g.node2degree[v] >= q.node2degree[u]:\n",
        "        flag = True\n",
        "        for node in q.phi:\n",
        "          if node == u:\n",
        "            break\n",
        "          if node == q.phiparent[u]:\n",
        "            continue\n",
        "          #if m[node] not in g.edges[v]:\n",
        "          if v == m[node] or (m[node] not in g.edges[v] and (node in q.edges[u] or u in q.edges[node])):\n",
        "            flag = False\n",
        "            break\n",
        "        if flag:\n",
        "          lc.add(v)\n",
        "\n",
        "  for node in lc:\n",
        "    if node not in set(m.values()):\n",
        "      m[u] = node\n",
        "      DAF_EP(q, g, m, i + 1, totalresult)\n",
        "      m.pop(u)\"\"\"\n",
        "\n",
        "def DAF_EP(q, g, m, totalresult, edgematrix):\n",
        "  class infomation(object):\n",
        "    def __init__(self, node, degree, weight):\n",
        "      self.node = node\n",
        "      self.degree = degree\n",
        "      self.weight = weight\n",
        "    def __lt__(self, other):\n",
        "      if self.degree == 1 and other.degree == 1:\n",
        "        return True\n",
        "      elif self.degree != 1 and other.degree == 1:\n",
        "        return False\n",
        "      else:\n",
        "        return self.weight > other.weight\n",
        "\n",
        "  def updateextendablenode(q, m, mappednode, extendable, rankqueue, validcandidate, edgematrix, idcount, tempbuffer):\n",
        "    for node in q.dagchildren[mappednode]:\n",
        "      extendable[node] -= 1\n",
        "      if extendable[node] == 0:\n",
        "        \n",
        "        bns = list(q.dagparents[node])\n",
        "        validcandidate[node] = set()\n",
        "        prebn = bns[0]\n",
        "        validcandidate[node] |= edgematrix[prebn][node][m[prebn]]\n",
        "\n",
        "        for i, curbn in enumerate(bns):\n",
        "          if i == 0:\n",
        "            continue\n",
        "          curcandidates = edgematrix[curbn][node][m[curbn]]\n",
        "\n",
        "          tempbuffer = validcandidate[node] & curcandidates\n",
        "          \n",
        "          tmp = tempbuffer\n",
        "          tempbuffer = validcandidate[node]\n",
        "          validcandidate[node] = tmp\n",
        "        \n",
        "        idcount[node] = len(validcandidate[node])\n",
        "\n",
        "\n",
        "        weight = 0\n",
        "        for candidate in validcandidate[node]:\n",
        "          weight += q.weights[node][candidate]\n",
        "\n",
        "        rankqueue[-1].put(infomation(node, q.node2degree[node], weight))\n",
        "\n",
        "  extendable = {}\n",
        "  for node in q.node2label:\n",
        "    extendable[node] = len(q.dagparents[node])\n",
        "  \n",
        "  ancestors = defaultdict(set)\n",
        "  for qnode in q.phi:\n",
        "    ancestors[qnode].add(qnode)\n",
        "    for qparent in q.dagparents[qnode]:\n",
        "      ancestors[qnode] |= ancestors[qparent]\n",
        "\n",
        "  failingset = defaultdict(set)\n",
        "  curdepth = 0\n",
        "  startnode = q.phi[0]\n",
        "  visited = set()\n",
        "  reversem = {}\n",
        "  rankqueue = []\n",
        "  validcandidate = defaultdict(set)\n",
        "  tempbuffer = set()\n",
        "  idx = {}\n",
        "  idcount = {}\n",
        "  maxdepth = len(q.node2label)\n",
        "  for gnode in q.candidateset[startnode]:\n",
        "    m[startnode] = gnode\n",
        "    visited.add(gnode)\n",
        "    reversem[gnode] = startnode\n",
        "    pq = PriorityQueue()\n",
        "    rankqueue.append(pq)\n",
        "    updateextendablenode(q, m, startnode, extendable, rankqueue, validcandidate, edgematrix, idcount, tempbuffer)\n",
        "    u = rankqueue[-1].get().node\n",
        "\n",
        "    if idcount[u] == 0:\n",
        "      failingset[curdepth] = ancestors[u]\n",
        "    else:\n",
        "      failingset[curdepth] = set()\n",
        "\n",
        "    curdepth += 1\n",
        "    q.phi[curdepth] = u\n",
        "    idx[u] = 0\n",
        "    while curdepth > 0:\n",
        "      while idx[u] < idcount[u]:\n",
        "\n",
        "        candidatelist = list(validcandidate[u])\n",
        "        validnode = candidatelist[idx[u]]\n",
        "        \n",
        "        if validnode in visited:\n",
        "          idx[u] += 1\n",
        "          failingset[curdepth] = ancestors[u]\n",
        "          failingset[curdepth] |= ancestors[reversem[validnode]]\n",
        "          failingset[curdepth - 1] |= failingset[curdepth]\n",
        "\n",
        "          continue\n",
        "        \n",
        "        m[u] = validnode\n",
        "        visited.add(validnode)\n",
        "        idx[u] += 1\n",
        "        reversem[validnode] = u\n",
        "\n",
        "        if curdepth == maxdepth - 1:\n",
        "          totalresult.append(m.copy())\n",
        "          visited.remove(validnode)\n",
        "          reversem.pop(m[u])\n",
        "\n",
        "          for qnode in q.node2label:\n",
        "            failingset[curdepth].add(qnode)\n",
        "\n",
        "          failingset[curdepth - 1] |= failingset[curdepth]\n",
        "        else:\n",
        "          curdepth += 1\n",
        "          copydp = PriorityQueue()\n",
        "          copydp.queue = deepcopy(rankqueue[-1].queue)\n",
        "          rankqueue.append(copydp)\n",
        "          updateextendablenode(q, m, u, extendable, rankqueue, validcandidate, edgematrix, idcount, tempbuffer)\n",
        "          u = rankqueue[-1].get().node\n",
        "          idx[u] = 0\n",
        "          q.phi[curdepth] = u\n",
        "\n",
        "          if idcount[u] == 0:\n",
        "            failingset[curdepth - 1] = ancestors[u]\n",
        "          else:\n",
        "            failingset[curdepth - 1] = set()\n",
        "      \n",
        "      curdepth -= 1\n",
        "      rankqueue.pop(-1)\n",
        "      u = q.phi[curdepth]\n",
        "      visited.remove(m[u])\n",
        "\n",
        "      for children in q.dagchildren[u]:\n",
        "        extendable[children] += 1\n",
        "\n",
        "      reversem.pop(m[u])\n",
        "      if curdepth != 0:\n",
        "        if u not in failingset[curdepth]:\n",
        "          failingset[curdepth - 1] = failingset[curdepth]\n",
        "          idx[u] = idcount[u]\n",
        "        else:\n",
        "          failingset[curdepth - 1] |= failingset[curdepth]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZIr5JFjEd4O",
        "outputId": "2128cd77-d337-41a3-ad39-aab710582c8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "query_dense_16_37.graph\n",
            "query_dense_16_66.graph\n",
            "query_dense_16_72.graph\n",
            "query_dense_16_79.graph\n",
            "query_dense_16_152.graph\n",
            "query_dense_16_44.graph\n",
            "query_dense_16_126.graph\n",
            "query_dense_16_49.graph\n",
            "query_dense_16_38.graph\n",
            "query_dense_16_175.graph\n",
            "query_dense_16_19.graph\n",
            "query_dense_16_67.graph\n",
            "query_dense_16_108.graph\n",
            "query_dense_16_177.graph\n",
            "query_dense_16_7.graph\n",
            "query_dense_16_34.graph\n",
            "query_dense_16_48.graph\n",
            "query_dense_16_71.graph\n",
            "query_dense_16_28.graph\n",
            "query_dense_16_41.graph\n",
            "query_dense_16_39.graph\n",
            "query_dense_16_145.graph\n",
            "query_dense_16_143.graph\n",
            "query_dense_16_179.graph\n",
            "query_dense_16_199.graph\n",
            "query_dense_16_42.graph\n",
            "query_dense_16_127.graph\n",
            "query_dense_16_166.graph\n",
            "query_dense_16_95.graph\n",
            "query_dense_16_194.graph\n",
            "query_dense_16_161.graph\n",
            "query_dense_16_157.graph\n",
            "query_dense_16_168.graph\n",
            "query_dense_16_77.graph\n",
            "query_dense_16_74.graph\n",
            "query_dense_16_142.graph\n",
            "query_dense_16_2.graph\n",
            "query_dense_16_130.graph\n",
            "query_dense_16_87.graph\n",
            "query_dense_16_69.graph\n",
            "query_dense_16_6.graph\n",
            "query_dense_16_113.graph\n",
            "query_dense_16_64.graph\n",
            "query_dense_16_193.graph\n",
            "query_dense_16_180.graph\n",
            "query_dense_16_20.graph\n",
            "query_dense_16_185.graph\n",
            "query_dense_16_200.graph\n",
            "query_dense_16_46.graph\n",
            "query_dense_16_139.graph\n",
            "query_dense_16_62.graph\n",
            "query_dense_16_151.graph\n",
            "query_dense_16_132.graph\n",
            "query_dense_16_146.graph\n",
            "query_dense_16_56.graph\n",
            "query_dense_16_162.graph\n",
            "query_dense_16_33.graph\n",
            "query_dense_16_16.graph\n",
            "query_dense_16_82.graph\n",
            "query_dense_16_86.graph\n",
            "query_dense_16_29.graph\n",
            "query_dense_16_85.graph\n",
            "query_dense_16_109.graph\n",
            "query_dense_16_70.graph\n",
            "query_dense_16_115.graph\n",
            "query_dense_16_30.graph\n",
            "query_dense_16_106.graph\n",
            "query_dense_16_150.graph\n",
            "query_dense_16_195.graph\n",
            "query_dense_16_1.graph\n",
            "query_dense_16_96.graph\n",
            "query_dense_16_100.graph\n",
            "query_dense_16_116.graph\n",
            "query_dense_16_53.graph\n",
            "query_dense_16_8.graph\n",
            "query_dense_16_148.graph\n",
            "query_dense_16_75.graph\n",
            "query_dense_16_101.graph\n",
            "query_dense_16_173.graph\n",
            "query_dense_16_154.graph\n",
            "query_dense_16_129.graph\n",
            "query_dense_16_93.graph\n",
            "query_dense_16_149.graph\n",
            "query_dense_16_107.graph\n",
            "query_dense_16_163.graph\n",
            "query_dense_16_22.graph\n",
            "query_dense_16_188.graph\n",
            "query_dense_16_159.graph\n",
            "query_dense_16_14.graph\n",
            "query_dense_16_12.graph\n",
            "query_dense_16_17.graph\n",
            "query_dense_16_4.graph\n",
            "query_dense_16_169.graph\n",
            "query_dense_16_90.graph\n",
            "query_dense_16_83.graph\n",
            "query_dense_16_63.graph\n",
            "query_dense_16_36.graph\n",
            "query_dense_16_181.graph\n",
            "query_dense_16_135.graph\n",
            "query_dense_16_124.graph\n",
            "query_dense_16_137.graph\n",
            "query_dense_16_112.graph\n",
            "query_dense_16_121.graph\n",
            "query_dense_16_43.graph\n",
            "query_dense_16_54.graph\n",
            "query_dense_16_147.graph\n",
            "query_dense_16_186.graph\n",
            "query_dense_16_61.graph\n",
            "query_dense_16_84.graph\n",
            "query_dense_16_119.graph\n",
            "query_dense_16_68.graph\n",
            "query_dense_16_47.graph\n",
            "query_dense_16_184.graph\n",
            "query_dense_16_58.graph\n",
            "query_dense_16_94.graph\n",
            "query_dense_16_197.graph\n",
            "query_dense_16_32.graph\n",
            "query_dense_16_9.graph\n",
            "query_dense_16_131.graph\n",
            "query_dense_16_140.graph\n",
            "query_dense_16_99.graph\n",
            "query_dense_16_192.graph\n",
            "query_dense_16_5.graph\n",
            "query_dense_16_158.graph\n",
            "query_dense_16_103.graph\n",
            "query_dense_16_104.graph\n",
            "query_dense_16_97.graph\n",
            "query_dense_16_105.graph\n",
            "query_dense_16_171.graph\n",
            "query_dense_16_155.graph\n",
            "query_dense_16_52.graph\n",
            "query_dense_16_23.graph\n",
            "query_dense_16_45.graph\n",
            "query_dense_16_123.graph\n",
            "query_dense_16_76.graph\n",
            "query_dense_16_136.graph\n",
            "query_dense_16_25.graph\n",
            "query_dense_16_50.graph\n",
            "query_dense_16_80.graph\n",
            "query_dense_16_98.graph\n",
            "query_dense_16_57.graph\n",
            "query_dense_16_134.graph\n",
            "query_dense_16_102.graph\n",
            "query_dense_16_73.graph\n",
            "query_dense_16_81.graph\n",
            "query_dense_16_190.graph\n",
            "query_dense_16_55.graph\n",
            "query_dense_16_117.graph\n",
            "query_dense_16_114.graph\n",
            "query_dense_16_138.graph\n",
            "query_dense_16_91.graph\n",
            "query_dense_16_15.graph\n",
            "query_dense_16_120.graph\n",
            "query_dense_16_60.graph\n",
            "query_dense_16_125.graph\n",
            "query_dense_16_165.graph\n",
            "query_dense_16_183.graph\n",
            "query_dense_16_92.graph\n",
            "query_dense_16_178.graph\n",
            "query_dense_16_198.graph\n",
            "query_dense_16_141.graph\n",
            "query_dense_16_167.graph\n",
            "query_dense_16_35.graph\n",
            "query_dense_16_78.graph\n",
            "query_dense_16_174.graph\n",
            "query_dense_16_11.graph\n",
            "query_dense_16_10.graph\n",
            "query_dense_16_65.graph\n",
            "query_dense_16_13.graph\n",
            "query_dense_16_21.graph\n",
            "query_dense_16_133.graph\n",
            "query_dense_16_153.graph\n",
            "query_dense_16_172.graph\n",
            "query_dense_16_88.graph\n",
            "query_dense_16_110.graph\n",
            "query_dense_16_182.graph\n",
            "query_dense_16_191.graph\n",
            "query_dense_16_128.graph\n",
            "query_dense_16_59.graph\n",
            "query_dense_16_51.graph\n",
            "query_dense_16_144.graph\n",
            "query_dense_16_196.graph\n",
            "query_dense_16_31.graph\n",
            "query_dense_16_187.graph\n",
            "query_dense_16_170.graph\n",
            "query_dense_16_27.graph\n",
            "query_dense_16_26.graph\n",
            "query_dense_16_122.graph\n",
            "query_dense_16_89.graph\n",
            "query_dense_16_111.graph\n",
            "query_dense_16_189.graph\n",
            "query_dense_16_18.graph\n",
            "query_dense_16_156.graph\n",
            "query_dense_16_176.graph\n",
            "query_dense_16_118.graph\n",
            "query_dense_16_164.graph\n",
            "query_dense_16_160.graph\n",
            "query_dense_16_3.graph\n",
            "query_dense_16_40.graph\n",
            "query_dense_16_24.graph\n",
            "{'query_dense_16_37.graph': 1, 'query_dense_16_66.graph': 3, 'query_dense_16_72.graph': 24, 'query_dense_16_79.graph': 2, 'query_dense_16_152.graph': 432, 'query_dense_16_44.graph': 12, 'query_dense_16_126.graph': 156, 'query_dense_16_49.graph': 178, 'query_dense_16_38.graph': 180, 'query_dense_16_175.graph': 8, 'query_dense_16_19.graph': 2, 'query_dense_16_67.graph': 1, 'query_dense_16_108.graph': 46, 'query_dense_16_177.graph': 72, 'query_dense_16_7.graph': 2, 'query_dense_16_34.graph': 2, 'query_dense_16_48.graph': 4, 'query_dense_16_71.graph': 9, 'query_dense_16_28.graph': 5, 'query_dense_16_41.graph': 8, 'query_dense_16_39.graph': 1, 'query_dense_16_145.graph': 1, 'query_dense_16_143.graph': 4, 'query_dense_16_179.graph': 184, 'query_dense_16_199.graph': 2, 'query_dense_16_42.graph': 32, 'query_dense_16_127.graph': 12, 'query_dense_16_166.graph': 128, 'query_dense_16_95.graph': 354, 'query_dense_16_194.graph': 1, 'query_dense_16_161.graph': 44, 'query_dense_16_157.graph': 2, 'query_dense_16_168.graph': 75, 'query_dense_16_77.graph': 4, 'query_dense_16_74.graph': 8, 'query_dense_16_142.graph': 16, 'query_dense_16_2.graph': 80, 'query_dense_16_130.graph': 16, 'query_dense_16_87.graph': 12, 'query_dense_16_69.graph': 1, 'query_dense_16_6.graph': 132, 'query_dense_16_113.graph': 6, 'query_dense_16_64.graph': 1, 'query_dense_16_193.graph': 2, 'query_dense_16_180.graph': 1, 'query_dense_16_20.graph': 2, 'query_dense_16_185.graph': 44, 'query_dense_16_200.graph': 4, 'query_dense_16_46.graph': 30, 'query_dense_16_139.graph': 12, 'query_dense_16_62.graph': 8, 'query_dense_16_151.graph': 138, 'query_dense_16_132.graph': 20, 'query_dense_16_146.graph': 24, 'query_dense_16_56.graph': 4, 'query_dense_16_162.graph': 48, 'query_dense_16_33.graph': 4, 'query_dense_16_16.graph': 4, 'query_dense_16_82.graph': 12, 'query_dense_16_86.graph': 1, 'query_dense_16_29.graph': 24, 'query_dense_16_85.graph': 19, 'query_dense_16_109.graph': 68, 'query_dense_16_70.graph': 42, 'query_dense_16_115.graph': 10, 'query_dense_16_30.graph': 2, 'query_dense_16_106.graph': 2, 'query_dense_16_150.graph': 6, 'query_dense_16_195.graph': 2, 'query_dense_16_1.graph': 3, 'query_dense_16_96.graph': 17, 'query_dense_16_100.graph': 16, 'query_dense_16_116.graph': 1, 'query_dense_16_53.graph': 12, 'query_dense_16_8.graph': 560, 'query_dense_16_148.graph': 2, 'query_dense_16_75.graph': 32, 'query_dense_16_101.graph': 2, 'query_dense_16_173.graph': 24, 'query_dense_16_154.graph': 12, 'query_dense_16_129.graph': 8, 'query_dense_16_93.graph': 22, 'query_dense_16_149.graph': 1, 'query_dense_16_107.graph': 21, 'query_dense_16_163.graph': 8, 'query_dense_16_22.graph': 9, 'query_dense_16_188.graph': 8, 'query_dense_16_159.graph': 12, 'query_dense_16_14.graph': 2, 'query_dense_16_12.graph': 2, 'query_dense_16_17.graph': 4, 'query_dense_16_4.graph': 6, 'query_dense_16_169.graph': 44, 'query_dense_16_90.graph': 1564, 'query_dense_16_83.graph': 3, 'query_dense_16_63.graph': 44, 'query_dense_16_36.graph': 3, 'query_dense_16_181.graph': 8, 'query_dense_16_135.graph': 6, 'query_dense_16_124.graph': 2, 'query_dense_16_137.graph': 5, 'query_dense_16_112.graph': 2, 'query_dense_16_121.graph': 30, 'query_dense_16_43.graph': 3, 'query_dense_16_54.graph': 33, 'query_dense_16_147.graph': 1526, 'query_dense_16_186.graph': 10, 'query_dense_16_61.graph': 40, 'query_dense_16_84.graph': 8, 'query_dense_16_119.graph': 8, 'query_dense_16_68.graph': 256, 'query_dense_16_47.graph': 16, 'query_dense_16_184.graph': 60, 'query_dense_16_58.graph': 3, 'query_dense_16_94.graph': 2, 'query_dense_16_197.graph': 8, 'query_dense_16_32.graph': 2, 'query_dense_16_9.graph': 42, 'query_dense_16_131.graph': 3, 'query_dense_16_140.graph': 8, 'query_dense_16_99.graph': 260, 'query_dense_16_192.graph': 4, 'query_dense_16_5.graph': 4, 'query_dense_16_158.graph': 2, 'query_dense_16_103.graph': 48, 'query_dense_16_104.graph': 38, 'query_dense_16_97.graph': 56, 'query_dense_16_105.graph': 2, 'query_dense_16_171.graph': 14, 'query_dense_16_155.graph': 16, 'query_dense_16_52.graph': 6, 'query_dense_16_23.graph': 6, 'query_dense_16_45.graph': 8, 'query_dense_16_123.graph': 1, 'query_dense_16_76.graph': 41, 'query_dense_16_136.graph': 1, 'query_dense_16_25.graph': 4, 'query_dense_16_50.graph': 88, 'query_dense_16_80.graph': 13, 'query_dense_16_98.graph': 8, 'query_dense_16_57.graph': 3, 'query_dense_16_134.graph': 17, 'query_dense_16_102.graph': 8, 'query_dense_16_73.graph': 6, 'query_dense_16_81.graph': 124, 'query_dense_16_190.graph': 3, 'query_dense_16_55.graph': 1, 'query_dense_16_117.graph': 4, 'query_dense_16_114.graph': 4, 'query_dense_16_138.graph': 12, 'query_dense_16_91.graph': 3, 'query_dense_16_15.graph': 60, 'query_dense_16_120.graph': 24, 'query_dense_16_60.graph': 10, 'query_dense_16_125.graph': 8, 'query_dense_16_165.graph': 208, 'query_dense_16_183.graph': 4, 'query_dense_16_92.graph': 18, 'query_dense_16_178.graph': 1, 'query_dense_16_198.graph': 15, 'query_dense_16_141.graph': 20, 'query_dense_16_167.graph': 6, 'query_dense_16_35.graph': 2, 'query_dense_16_78.graph': 12, 'query_dense_16_174.graph': 6, 'query_dense_16_11.graph': 288, 'query_dense_16_10.graph': 32, 'query_dense_16_65.graph': 2, 'query_dense_16_13.graph': 12, 'query_dense_16_21.graph': 2, 'query_dense_16_133.graph': 6, 'query_dense_16_153.graph': 10, 'query_dense_16_172.graph': 16, 'query_dense_16_88.graph': 12, 'query_dense_16_110.graph': 2, 'query_dense_16_182.graph': 54, 'query_dense_16_191.graph': 4, 'query_dense_16_128.graph': 104, 'query_dense_16_59.graph': 1680, 'query_dense_16_51.graph': 50, 'query_dense_16_144.graph': 1, 'query_dense_16_196.graph': 2, 'query_dense_16_31.graph': 8, 'query_dense_16_187.graph': 2, 'query_dense_16_170.graph': 18, 'query_dense_16_27.graph': 8, 'query_dense_16_26.graph': 17, 'query_dense_16_122.graph': 16, 'query_dense_16_89.graph': 12, 'query_dense_16_111.graph': 2, 'query_dense_16_189.graph': 1, 'query_dense_16_18.graph': 2, 'query_dense_16_156.graph': 6, 'query_dense_16_176.graph': 12, 'query_dense_16_118.graph': 136, 'query_dense_16_164.graph': 480, 'query_dense_16_160.graph': 2688, 'query_dense_16_3.graph': 8, 'query_dense_16_40.graph': 12, 'query_dense_16_24.graph': 12}\n"
          ]
        }
      ],
      "source": [
        "queries = {}\n",
        "for g in gs:\n",
        "  for q in qs:\n",
        "    q.reset()\n",
        "    \n",
        "    DAF_CSG(q, g, 3)\n",
        "    edgematrix = DAF_MOG(q, g)\n",
        "    totalresult = []\n",
        "    print(q.graphid)\n",
        "    DAF_EP(q, g, {}, totalresult, edgematrix)\n",
        "    #DAF_EP(q, g, {}, 1, totalresult)\n",
        "    queries[q.graphid] = len(totalresult)\n",
        "\n",
        "print(queries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ngubn1FEgK5"
      },
      "outputs": [],
      "source": [
        "flag = True\n",
        "for name in expects:\n",
        "  if expects[name] != queries[name]:\n",
        "    print(name)\n",
        "    flag = False\n",
        "if flag:\n",
        "  print(\"correct\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Efficient Subgraph Matching: Harmonizing Dynamic Programming, Adaptive Matching Order, and Failing Set Together",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}