{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Efficient Subgraph Matching by Postponing Cartesian Products",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**CFL**"
      ],
      "metadata": {
        "id": "f4YDxgqeEWLA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a complex algorithm for subgraph matching. It proposed a new structure to reduce the search sapce.\n",
        "\n",
        "Also, this algorithm follow the classic three-step algorithm in the field of subgraph matching. The basic idea for this algorithm is that the authors want to reduce the search space of **non-tree edges**(the ones not in the BFS tree of the graph) by checking them as early as possible.\n",
        "\n",
        "First, in the candidate set generation part, the authors use **forward passing and backward refining** to construct CPI(candidate set) for each node. And also, they generate a special structure **N[qnode][gnodeparent][gnode]**, where gnodes are the candidates of qnode and gnodeparent are the parent of gnode in the matching algorithm.\n",
        "\n",
        "To construct CPI and N, the authors constructed **BFS tree** for the graph. For each level of the tree, we check the nodes in this level to see which ones in data graph could match with them. The forward candidate generation part mainly means: **a data vertex v is in u.C\n",
        "only if for each $u^{'}$ $\\in$ u.N, there is a data vertex $v^{'}$ $\\in$ $u^{'}$.C that is adjacent to v.**(what the cnt for). After this, they use a backward candidate pruning: **for each query vertex u based on its set of unvisited neighbors (i.e., u.UN), which were not exploited in the forward processing.** Also, they construct **N** in this forward part by find parents for candidate set for each level of nodes.(backward pruning is considered in forward part). \n",
        "\n",
        "In the backward refining part, they **exploit the candidate sets of lower-level neighbors of u to prune unpromising candidates from u.C** like in the forward part. And also, they update **N** accordingly.\n",
        "\n",
        "Then they try to generate a optimal matching order based on BFS tree we genereated before. They first classify the nodes into three structures: **core-structure, forest-structure, and leaf-structure** to reduce the search space by checking non-tree edges as early as possible(in the core part). They generate sub-orders for three structures separately using N they generated before. \n",
        "\n",
        "And finally, they use these three parts to enumerate to search the **corresponding map** and combine them(this way reduces the search space by removing some false path backward). For simplicity, I first combine the three sub-orders, and perform enumeration. The authors perfer to first iterate then combine(Easy to change with each other). \n",
        "\n",
        "The original enumeration part doesn't work correctly, so I change it like the one in the survey paper."
      ],
      "metadata": {
        "id": "0iSX0lkSEWW9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-F-4o-mJ2rCu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57e59006-1319-485d-88d5-b15f54a4bb12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'SubgraphMatching' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/RapidsAtHKUST/SubgraphMatching.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "zcSgzwdG56iM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class graph():\n",
        "  def __init__(self, graphid, node2label, node2degree, edges):\n",
        "    self.graphid = graphid\n",
        "    self.node2label = node2label\n",
        "    self.node2degree = node2degree\n",
        "    self.edges = edges\n",
        "    self.candidateset = defaultdict(set)\n",
        "    self.label2node = defaultdict(set)\n",
        "    for node in self.node2label:\n",
        "      self.label2node[self.node2label[node]].add(node)\n",
        "    self.phi = []\n",
        "    self.phiparent = {}\n",
        "\n",
        "  def reset(self):\n",
        "    self.candidateset = defaultdict(set)\n",
        "    self.phi = []\n",
        "    self.phiparent = {}"
      ],
      "metadata": {
        "id": "ry5KEaLj58Ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_graph(filepath, filename):\n",
        "  global qcount\n",
        "  global gcount\n",
        "\n",
        "  node2label = {}\n",
        "  node2degree = {}\n",
        "  edges = defaultdict(set)\n",
        "  f = open(filepath, \"r\", encoding=\"utf-8\")\n",
        "\n",
        "  _, nodenum, edgenum = f.readline().strip().split()\n",
        "  for i in range(int(nodenum)):\n",
        "    _, nodeid, nodelabel, nodedegree = f.readline().strip().split()\n",
        "    node2label[int(nodeid)] = int(nodelabel)\n",
        "    node2degree[int(nodeid)] = int(nodedegree)  \n",
        "  for i in range(int(edgenum)):\n",
        "    _, node1, node2 = f.readline().strip().split()\n",
        "    edges[int(node1)].add(int(node2))\n",
        "    edges[int(node2)].add(int(node1))\n",
        "\n",
        "  f.close()\n",
        "  g = graph(filename, node2label, node2degree, edges)\n",
        "\n",
        "  return g"
      ],
      "metadata": {
        "id": "URKqAe3x59IN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qcount = 0\n",
        "gcount = 0\n",
        "\n",
        "import os\n",
        "qs = []\n",
        "qdir = \"SubgraphMatching/test/query_graph\"\n",
        "for f in os.listdir(qdir):\n",
        "  filepath = os.path.join(qdir, f)\n",
        "  qs.append(get_graph(filepath, f))\n",
        "\n",
        "gs = []\n",
        "gdir = \"SubgraphMatching/test/data_graph\"\n",
        "for f in os.listdir(gdir):\n",
        "  filepath = os.path.join(gdir, f)\n",
        "  gs.append(get_graph(filepath, f))\n",
        "\n",
        "print(len(qs))\n",
        "print(len(gs))\n",
        "\n",
        "f = open(\"SubgraphMatching/test/expected_output.res\", \"r\", encoding=\"utf-8\")\n",
        "lines = f.readlines()\n",
        "f.close()\n",
        "\n",
        "expects = {}\n",
        "for line in lines:\n",
        "  name, times = line.strip().split(\":\")\n",
        "  expects[name + \".graph\"] = int(times)\n",
        "print(len(expects))"
      ],
      "metadata": {
        "id": "Gen49xMG5-KZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e7b9ba6-4e4d-4316-e02a-d1a5b28e407b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "1\n",
            "200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def CFL_CSG(q, g):\n",
        "  vc = set()\n",
        "  vt = set()\n",
        "  vl = set()\n",
        "\n",
        "  degrees = q.node2degree.copy()\n",
        "  for node in degrees:\n",
        "    vc.add(node)\n",
        "    vl.add(node)\n",
        "    vt.add(node)\n",
        "\n",
        "  flag = True\n",
        "  while(flag):\n",
        "    flag = False\n",
        "    for node in degrees:\n",
        "      if degrees[node] == 1 and node in vc:\n",
        "        vc.remove(node)\n",
        "        flag = True\n",
        "        for neighbor in q.edges[node]:\n",
        "          if degrees[neighbor] > 0:\n",
        "            degrees[neighbor] -= 1\n",
        "\n",
        "  \n",
        "  for node in q.node2degree:\n",
        "    if q.node2degree[node] != 1 and node in vl:\n",
        "      vl.remove(node)\n",
        "  vl -= vc\n",
        "\n",
        "  vt -= vc\n",
        "  vt -= vl\n",
        "\n",
        "\n",
        "\n",
        "  for qnode in vc:\n",
        "    label = q.node2label[qnode]\n",
        "    for gnode in g.label2node[label]:\n",
        "      if q.node2degree[qnode] <= g.node2degree[gnode]:\n",
        "        q.candidateset[qnode].add(gnode)\n",
        "  \n",
        "  roots = {}\n",
        "  for qnode in vc:\n",
        "    roots[qnode] = len(q.candidateset[qnode]) / q.node2degree[qnode]\n",
        "  roots = sorted(roots.items(), key = lambda kv: kv[1])\n",
        "  roots = roots[:3]\n",
        "  rs = set()\n",
        "  for root in roots:\n",
        "    rs.add(root[0])\n",
        "  \n",
        "  qmaxneighbordegrees = {}\n",
        "  for qnode in q.node2degree:\n",
        "    maxdegree = 0\n",
        "    for neighbor in q.edges[qnode]:\n",
        "      maxdegree = max(maxdegree, q.node2degree[neighbor])\n",
        "    qmaxneighbordegrees[qnode] = maxdegree\n",
        "  \n",
        "  gmaxneighbordegrees = {}\n",
        "  for gnode in g.node2degree:\n",
        "    maxdegree = 0\n",
        "    for neighbor in g.edges[gnode]:\n",
        "      maxdegree = max(maxdegree, g.node2degree[neighbor])\n",
        "    gmaxneighbordegrees[gnode] = maxdegree\n",
        "  \n",
        "  for qnode in rs:\n",
        "    for gnode in q.candidateset[qnode].copy():\n",
        "      if gmaxneighbordegrees[gnode] < qmaxneighbordegrees[qnode]:\n",
        "        q.candidateset[qnode].remove(gnode)\n",
        "\n",
        "  \n",
        "  roots = {}\n",
        "  for r in rs:\n",
        "    roots[r] = len(q.candidateset[r]) / q.node2degree[r]\n",
        "  roots = sorted(roots.items(), key = lambda kv: kv[1])\n",
        "  r = roots[0][0]\n",
        "\n",
        "  q.reset()\n",
        "  for gnode in g.label2node[q.node2label[r]]:\n",
        "    if q.node2degree[r] <= g.node2degree[gnode]:\n",
        "      if gmaxneighbordegrees[gnode] >= qmaxneighbordegrees[r]:\n",
        "        q.candidateset[r].add(gnode)\n",
        "  \n",
        "  node2level = {}\n",
        "  visited = set()\n",
        "  queue = []\n",
        "  visited.add(r)\n",
        "  node2level[r] = 1\n",
        "  maxlevel = 1\n",
        "  queue.append(r)\n",
        "  nodeparent = {}\n",
        "  nodeparent[r] = -1\n",
        "  nodechildren = defaultdict(set)\n",
        "  while queue:\n",
        "    top = queue[0]\n",
        "    queue.pop(0)\n",
        "    for neighbor in q.edges[top]:\n",
        "      if neighbor not in visited:\n",
        "        node2level[neighbor] = node2level[top] + 1\n",
        "        nodeparent[neighbor] = top\n",
        "        nodechildren[top].add(neighbor)\n",
        "        maxlevel = max(maxlevel, node2level[neighbor])\n",
        "        visited.add(neighbor)\n",
        "        queue.append(neighbor)\n",
        "  \n",
        "  level2node = defaultdict(set)\n",
        "  for node in node2level:\n",
        "    level2node[node2level[node]].add(node)\n",
        "\n",
        "  cnts = {}\n",
        "  for gnode in g.node2label:\n",
        "    cnts[gnode] = 0\n",
        "  \n",
        "  visited = set()\n",
        "  visited.add(r)\n",
        "  uns = defaultdict(set)\n",
        "  n = defaultdict(lambda: defaultdict(set))\n",
        "  for level in range(2, maxlevel + 1):\n",
        "    qnodes = []\n",
        "    for qnode in level2node[level]:\n",
        "      qnodes.append(qnode)\n",
        "      cnt = 0\n",
        "      for qneighbor in q.edges[qnode]:\n",
        "        if qneighbor not in visited and node2level[qneighbor] == level:\n",
        "          uns[qnode].add(qneighbor)\n",
        "        elif qneighbor in visited:\n",
        "          for gnode in q.candidateset[qneighbor]:\n",
        "            for gneighbor in g.edges[gnode]:\n",
        "              if g.node2label[gneighbor] == q.node2label[qnode] and g.node2degree[gneighbor] >= q.node2degree[qnode]:\n",
        "                if cnts[gneighbor] == cnt:\n",
        "                  cnts[gneighbor] = cnt + 1\n",
        "          cnt += 1\n",
        "\n",
        "      for gnode in g.node2label:\n",
        "        if cnts[gnode] == cnt:\n",
        "          if gmaxneighbordegrees[gnode] >= qmaxneighbordegrees[qnode]:\n",
        "            q.candidateset[qnode].add(gnode)\n",
        "      visited.add(qnode)\n",
        "      for gnode in cnts:\n",
        "        if cnts[gnode] > 0:\n",
        "          cnts[gnode] = 0\n",
        "\n",
        "    qnodes.reverse()\n",
        "    for qnode in qnodes:\n",
        "      cnt = 0\n",
        "      for qneighbor in uns[qnode]:\n",
        "        for gnode in q.candidateset[qneighbor]:\n",
        "          for gneighbor in g.edges[gnode]:\n",
        "            if g.node2label[gneighbor] == q.node2label[qnode] and g.node2degree[gneighbor] >= q.node2degree[qnode]:\n",
        "              if cnts[gneighbor] == cnt:\n",
        "                cnts[gneighbor] = cnt + 1\n",
        "        cnt += 1\n",
        "      for gnode in q.candidateset[qnode].copy():\n",
        "        if cnts[gnode] != cnt:\n",
        "          q.candidateset[qnode].remove(gnode)\n",
        "      for gnode in cnts:\n",
        "        if cnts[gnode] > 0:\n",
        "          cnts[gnode] = 0\n",
        "  \n",
        "    for qnode in level2node[level]:\n",
        "      qnodeparent = nodeparent[qnode]\n",
        "      for gnodeparent in q.candidateset[qnodeparent]:\n",
        "        for gnode in g.edges[gnodeparent]:\n",
        "          if g.node2label[gnode] == q.node2label[qnode] and gnode in q.candidateset[qnode]:\n",
        "            n[qnode][gnodeparent].add(gnode)\n",
        "\n",
        "\n",
        "  cnts = {}\n",
        "  for gnode in g.node2label:\n",
        "    cnts[gnode] = 0\n",
        "\n",
        "  for level in range(maxlevel, 0, -1):\n",
        "    for qnode in level2node[level]:\n",
        "      cnt = 0\n",
        "      for qneighbor in q.edges[qnode]:\n",
        "        if node2level[qneighbor] > level:\n",
        "          for gnode in q.candidateset[qneighbor]:\n",
        "            for gneighbor in g.edges[gnode]:\n",
        "              if g.node2label[gneighbor] == q.node2label[qnode] and g.node2degree[gneighbor] >= q.node2degree[qnode]:\n",
        "                if cnts[gneighbor] == cnt:\n",
        "                  cnts[gneighbor] = cnt + 1\n",
        "          cnt += 1\n",
        "      \n",
        "      tmp = q.candidateset[qnode].copy()#not equal to the paper, the paper means deal with these two at the same time, so I have to use a tmp to store the inital candidateset\n",
        "\n",
        "      for gnode in q.candidateset[qnode].copy():\n",
        "        if cnts[gnode] != cnt:\n",
        "          q.candidateset[qnode].remove(gnode)\n",
        "    \n",
        "      for gnode in cnts:\n",
        "        if cnts[gnode] > 0:\n",
        "          cnts[gnode] = 0\n",
        "\n",
        "\n",
        "      for gnode in tmp:\n",
        "        for qnodechild in nodechildren[qnode]:\n",
        "          for gnodechild in n[qnodechild][gnode].copy():\n",
        "            if gnodechild not in q.candidateset[qnodechild]:\n",
        "              n[qnodechild][gnode].remove(gnodechild)\n",
        "\n",
        "\n",
        "  return n, r, nodeparent, nodechildren, vc, vt, vl"
      ],
      "metadata": {
        "id": "kaGV_VUB6BbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CFL_MOG(q, n, r, nodeparent, nodechildren, vc, vt, vl):\n",
        "  \n",
        "  cpaths = []\n",
        "  tpaths = []\n",
        "  lpaths = []\n",
        "  \n",
        "  def dfs(cur, path):\n",
        "    if len(nodechildren[cur] & vc) == 0:\n",
        "      cpaths.append(path.copy())\n",
        "      return\n",
        "    \n",
        "    for child in nodechildren[cur]:\n",
        "      if child in vc:\n",
        "        path.append(child)\n",
        "        dfs(child, path)\n",
        "        path.pop(-1)\n",
        "  \n",
        "  dfs(r, [r])\n",
        "  \n",
        "  def ccalculate(path):\n",
        "    cs = {}\n",
        "    for parent in n[path[-1]]:\n",
        "      for child in n[path[-1]][parent]:\n",
        "        cs[child] = 1\n",
        "\n",
        "    for i in range(len(path) - 1, 0, -1):\n",
        "      cur = path[i]\n",
        "      for parent in n[cur]:\n",
        "        cs[parent] = 0\n",
        "        for child in n[cur][parent]:\n",
        "          cs[parent] += cs[child]\n",
        "    \n",
        "    c = 0\n",
        "    for node in cs:\n",
        "      if node in q.candidateset[path[0]]:\n",
        "        c += cs[node]\n",
        "    \n",
        "    return c\n",
        "\n",
        "  def gen_order(paths, v):\n",
        "    if not paths:\n",
        "      return []\n",
        "    cs = []\n",
        "    for path in paths:\n",
        "      cs.append(ccalculate(path) / (len(path) - 1))\n",
        "    visited = set()\n",
        "    minc = min(cs)\n",
        "    minindex = 0\n",
        "    addednodes = set()\n",
        "    for i, c in enumerate(cs):\n",
        "      if c == minc:\n",
        "        visited.add(i)\n",
        "        minindex = i\n",
        "        break\n",
        "    \n",
        "    order = []\n",
        "    for node in paths[i]:\n",
        "      if node in v:\n",
        "        order.append(node)\n",
        "        addednodes.add(node)\n",
        "\n",
        "    while len(visited) != len(paths):\n",
        "      cs = {}\n",
        "      for i, path in enumerate(paths):\n",
        "        if i not in visited:\n",
        "          j = 0\n",
        "          while(j < len(path)):\n",
        "            if path[j] not in addednodes:\n",
        "              break\n",
        "            j += 1\n",
        "          cs[i] = ccalculate(path[j:]) / len(q.candidateset[path[j]])\n",
        "      minc = cs[max(cs,key=cs.get)] + 1\n",
        "      minindex = -1\n",
        "      for i in cs:\n",
        "        if i not in visited and cs[i] < minc:\n",
        "          minc = c\n",
        "          minindex = i\n",
        "\n",
        "      visited.add(minindex)\n",
        "      start = 0\n",
        "      while(start < len(paths[minindex])):\n",
        "        if paths[minindex][start] not in addednodes:\n",
        "          break\n",
        "        start += 1\n",
        "\n",
        "      for i in range(start, len(paths[minindex])):\n",
        "        if paths[minindex][i] in v:\n",
        "          order.append(paths[minindex][i])\n",
        "          addednodes.add(paths[minindex][i])\n",
        "    return order\n",
        "  \n",
        "  def gen_path(v, vchild, paths):\n",
        "    for node in v:\n",
        "      for child in nodechildren[node]:\n",
        "        path = []\n",
        "        if child in vchild:\n",
        "          cur = child\n",
        "          path.append(cur)\n",
        "          while len(nodechildren[cur] & vchild):\n",
        "            cur = list(nodechildren[cur])[0]\n",
        "            if cur in vchild:\n",
        "              path.append(cur)\n",
        "        if path:\n",
        "          path.insert(0, node)\n",
        "          paths.append(path)\n",
        "\n",
        "  gen_path(vc, vt, tpaths)\n",
        "  gen_path(vc, vl, lpaths)\n",
        "  gen_path(vt, vl, lpaths)\n",
        "  cpath = gen_order(cpaths, vc)\n",
        "  tpath = gen_order(tpaths, vt)\n",
        "  lpath = gen_order(lpaths, vl)\n",
        "  q.phi = cpath + tpath + lpath\n",
        "  \n",
        "  for node in q.phi:\n",
        "    q.phiparent[node] = nodeparent[node]"
      ],
      "metadata": {
        "id": "K-wCm67i6FVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CFL_EP(q, g, m, i, totalresult): # not equal to the original code\n",
        "  if i == len(q.phi) + 1:\n",
        "    totalresult.append(m.copy())\n",
        "    return \n",
        "  result = {}\n",
        "  u = -1\n",
        "  for node in q.phi:\n",
        "    if node not in m:\n",
        "      u = node\n",
        "      break\n",
        "\n",
        "  lc = set()\n",
        "\n",
        "  if i == 1:\n",
        "    lc = q.candidateset[u]\n",
        "  elif q.phi.index(u) == 1:\n",
        "    lc = n[u][m[nodeparent[u]]]\n",
        "  else:\n",
        "    for v in n[u][m[nodeparent[u]]]:\n",
        "      flag = True\n",
        "      for node in q.phi:\n",
        "        if node == u:\n",
        "          break\n",
        "        if node == q.phiparent[u]:\n",
        "          continue\n",
        "        #if m[node] not in g.edges[v]:\n",
        "        if v == m[node] or (m[node] not in g.edges[v] and (node in q.edges[u] or u in q.edges[node])):\n",
        "          flag = False\n",
        "          break\n",
        "      if flag:\n",
        "        lc.add(v)\n",
        "\n",
        "  for node in lc:\n",
        "    if node not in set(m.values()):\n",
        "      m[u] = node\n",
        "      CFL_EP(q, g, m, i + 1, totalresult)\n",
        "      m.pop(u)"
      ],
      "metadata": {
        "id": "EfR0ZGvI6GzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries = {}\n",
        "for g in gs:\n",
        "  for q in qs:\n",
        "    q.reset()\n",
        "\n",
        "    n, r, nodeparent, nodechildren, vc, vt, vl = CFL_CSG(q, g)\n",
        "    CFL_MOG(q, n, r, nodeparent, nodechildren, vc, vt, vl)\n",
        "    totalresult = []\n",
        "    CFL_EP(q, g, {}, 1, totalresult)\n",
        "\n",
        "    queries[q.graphid] = len(totalresult)\n",
        "\n",
        "print(queries)"
      ],
      "metadata": {
        "id": "u_zS8H6K6IbL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ea784d0-e12d-4e82-fd0b-395e51c2c849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query_dense_16_41.graph': 8, 'query_dense_16_152.graph': 432, 'query_dense_16_44.graph': 12, 'query_dense_16_165.graph': 208, 'query_dense_16_77.graph': 4, 'query_dense_16_171.graph': 14, 'query_dense_16_62.graph': 8, 'query_dense_16_196.graph': 2, 'query_dense_16_60.graph': 10, 'query_dense_16_178.graph': 1, 'query_dense_16_100.graph': 16, 'query_dense_16_103.graph': 48, 'query_dense_16_136.graph': 1, 'query_dense_16_85.graph': 19, 'query_dense_16_40.graph': 12, 'query_dense_16_122.graph': 16, 'query_dense_16_172.graph': 16, 'query_dense_16_134.graph': 17, 'query_dense_16_67.graph': 1, 'query_dense_16_116.graph': 1, 'query_dense_16_10.graph': 32, 'query_dense_16_86.graph': 1, 'query_dense_16_22.graph': 9, 'query_dense_16_139.graph': 12, 'query_dense_16_89.graph': 12, 'query_dense_16_24.graph': 12, 'query_dense_16_71.graph': 9, 'query_dense_16_141.graph': 20, 'query_dense_16_151.graph': 138, 'query_dense_16_19.graph': 2, 'query_dense_16_36.graph': 3, 'query_dense_16_101.graph': 2, 'query_dense_16_106.graph': 2, 'query_dense_16_108.graph': 46, 'query_dense_16_49.graph': 178, 'query_dense_16_29.graph': 24, 'query_dense_16_161.graph': 44, 'query_dense_16_91.graph': 3, 'query_dense_16_98.graph': 8, 'query_dense_16_164.graph': 480, 'query_dense_16_68.graph': 256, 'query_dense_16_199.graph': 2, 'query_dense_16_48.graph': 4, 'query_dense_16_43.graph': 3, 'query_dense_16_30.graph': 2, 'query_dense_16_126.graph': 156, 'query_dense_16_84.graph': 8, 'query_dense_16_114.graph': 4, 'query_dense_16_195.graph': 2, 'query_dense_16_191.graph': 4, 'query_dense_16_25.graph': 4, 'query_dense_16_185.graph': 44, 'query_dense_16_104.graph': 38, 'query_dense_16_50.graph': 88, 'query_dense_16_88.graph': 12, 'query_dense_16_80.graph': 13, 'query_dense_16_160.graph': 2688, 'query_dense_16_183.graph': 4, 'query_dense_16_158.graph': 2, 'query_dense_16_123.graph': 1, 'query_dense_16_149.graph': 1, 'query_dense_16_7.graph': 2, 'query_dense_16_125.graph': 8, 'query_dense_16_112.graph': 2, 'query_dense_16_143.graph': 4, 'query_dense_16_46.graph': 30, 'query_dense_16_39.graph': 1, 'query_dense_16_17.graph': 4, 'query_dense_16_186.graph': 10, 'query_dense_16_59.graph': 1680, 'query_dense_16_51.graph': 50, 'query_dense_16_4.graph': 6, 'query_dense_16_146.graph': 24, 'query_dense_16_33.graph': 4, 'query_dense_16_121.graph': 30, 'query_dense_16_26.graph': 17, 'query_dense_16_42.graph': 32, 'query_dense_16_18.graph': 2, 'query_dense_16_3.graph': 8, 'query_dense_16_170.graph': 18, 'query_dense_16_65.graph': 2, 'query_dense_16_187.graph': 2, 'query_dense_16_102.graph': 8, 'query_dense_16_93.graph': 22, 'query_dense_16_2.graph': 80, 'query_dense_16_156.graph': 6, 'query_dense_16_61.graph': 40, 'query_dense_16_11.graph': 288, 'query_dense_16_45.graph': 8, 'query_dense_16_189.graph': 1, 'query_dense_16_177.graph': 72, 'query_dense_16_124.graph': 2, 'query_dense_16_82.graph': 12, 'query_dense_16_145.graph': 1, 'query_dense_16_73.graph': 6, 'query_dense_16_138.graph': 12, 'query_dense_16_99.graph': 260, 'query_dense_16_75.graph': 32, 'query_dense_16_120.graph': 24, 'query_dense_16_66.graph': 3, 'query_dense_16_23.graph': 6, 'query_dense_16_63.graph': 44, 'query_dense_16_175.graph': 8, 'query_dense_16_181.graph': 8, 'query_dense_16_57.graph': 3, 'query_dense_16_94.graph': 2, 'query_dense_16_168.graph': 75, 'query_dense_16_197.graph': 8, 'query_dense_16_127.graph': 12, 'query_dense_16_107.graph': 21, 'query_dense_16_153.graph': 10, 'query_dense_16_37.graph': 1, 'query_dense_16_96.graph': 17, 'query_dense_16_78.graph': 12, 'query_dense_16_38.graph': 180, 'query_dense_16_190.graph': 3, 'query_dense_16_95.graph': 354, 'query_dense_16_109.graph': 68, 'query_dense_16_131.graph': 3, 'query_dense_16_144.graph': 1, 'query_dense_16_110.graph': 2, 'query_dense_16_97.graph': 56, 'query_dense_16_92.graph': 18, 'query_dense_16_14.graph': 2, 'query_dense_16_157.graph': 2, 'query_dense_16_74.graph': 8, 'query_dense_16_47.graph': 16, 'query_dense_16_140.graph': 8, 'query_dense_16_8.graph': 560, 'query_dense_16_105.graph': 2, 'query_dense_16_167.graph': 6, 'query_dense_16_148.graph': 2, 'query_dense_16_159.graph': 12, 'query_dense_16_162.graph': 48, 'query_dense_16_169.graph': 44, 'query_dense_16_35.graph': 2, 'query_dense_16_174.graph': 6, 'query_dense_16_31.graph': 8, 'query_dense_16_154.graph': 12, 'query_dense_16_173.graph': 24, 'query_dense_16_6.graph': 132, 'query_dense_16_76.graph': 41, 'query_dense_16_176.graph': 12, 'query_dense_16_182.graph': 54, 'query_dense_16_52.graph': 6, 'query_dense_16_117.graph': 4, 'query_dense_16_20.graph': 2, 'query_dense_16_179.graph': 184, 'query_dense_16_115.graph': 10, 'query_dense_16_55.graph': 1, 'query_dense_16_135.graph': 6, 'query_dense_16_16.graph': 4, 'query_dense_16_70.graph': 42, 'query_dense_16_132.graph': 20, 'query_dense_16_12.graph': 2, 'query_dense_16_111.graph': 2, 'query_dense_16_184.graph': 60, 'query_dense_16_58.graph': 3, 'query_dense_16_32.graph': 2, 'query_dense_16_188.graph': 8, 'query_dense_16_53.graph': 12, 'query_dense_16_28.graph': 5, 'query_dense_16_194.graph': 1, 'query_dense_16_150.graph': 6, 'query_dense_16_27.graph': 8, 'query_dense_16_1.graph': 3, 'query_dense_16_21.graph': 2, 'query_dense_16_81.graph': 124, 'query_dense_16_137.graph': 5, 'query_dense_16_155.graph': 16, 'query_dense_16_147.graph': 1526, 'query_dense_16_129.graph': 8, 'query_dense_16_119.graph': 8, 'query_dense_16_180.graph': 1, 'query_dense_16_113.graph': 6, 'query_dense_16_200.graph': 4, 'query_dense_16_163.graph': 8, 'query_dense_16_15.graph': 60, 'query_dense_16_54.graph': 33, 'query_dense_16_9.graph': 42, 'query_dense_16_90.graph': 1564, 'query_dense_16_87.graph': 12, 'query_dense_16_72.graph': 24, 'query_dense_16_64.graph': 1, 'query_dense_16_130.graph': 16, 'query_dense_16_79.graph': 2, 'query_dense_16_69.graph': 1, 'query_dense_16_118.graph': 136, 'query_dense_16_166.graph': 128, 'query_dense_16_128.graph': 104, 'query_dense_16_198.graph': 15, 'query_dense_16_5.graph': 4, 'query_dense_16_192.graph': 4, 'query_dense_16_133.graph': 6, 'query_dense_16_83.graph': 3, 'query_dense_16_193.graph': 2, 'query_dense_16_34.graph': 2, 'query_dense_16_142.graph': 16, 'query_dense_16_13.graph': 12, 'query_dense_16_56.graph': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flag = True\n",
        "for name in expects:\n",
        "  if expects[name] != queries[name]:\n",
        "    print(name)\n",
        "    flag = False\n",
        "if flag:\n",
        "  print(\"correct\")"
      ],
      "metadata": {
        "id": "5dmjX12n6JEZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c120e073-4cb9-4218-9f49-7606b5b82a55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct\n"
          ]
        }
      ]
    }
  ]
}